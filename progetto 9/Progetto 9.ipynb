{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eddbb0ea",
   "metadata": {},
   "source": [
    "## FILTRO PER FAKE NEWS üîéüîé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22edfc7e",
   "metadata": {},
   "source": [
    "Il problema delle fake news √® cresciuto esponenzialmente nell'ultimo decennio a causa della crescente diffusione dei social network, il governo degli Stati Uniti ha deciso di muoversi a tal proposito, incaricando la tua azienda di realizzare un plug-in per chrome in grado di riconoscere se una notizia √® falsa. \n",
    "\n",
    "Il tuo compito √® quello di realizzare il modello in grado di riconoscere le notizie false, che poi il team di machine learning enginner e web developer metter√† in produzione.\n",
    "\n",
    "Ti vengono messi a disposizioni due raccolte di notizie, una contenente solo notizie false e l'altra contenente solo notizie vere, utilizzale per addestrare il tuo modello.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f1252",
   "metadata": {},
   "source": [
    "Parti da un'accurata analisi, rispondendo a domande come:\n",
    "\n",
    "* le fake news sono pi√π frequenti in una determinata categoria?\n",
    "* per ogni categoria, ci sono argomenti che sono pi√π soggetti alle fake news?\n",
    "* I titoli delle fake news presentano dei pattern?\n",
    "\n",
    "Una volta addestrato il modello esportalo utilizzando pickle cos√¨ che i tuoi colleghi possano metterlo in produzione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8ee2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas spacy nltk\n",
    "!python -m spacy download en_core_web_sm\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess as sp\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaMulticore\n",
    "from pprint import pprint\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "english_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = pd.read_csv(\"True.csv\")\n",
    "df_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974452d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d5065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv(\"Fake.csv\")\n",
    "df_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b195638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efabfc9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_subjects = df_true['subject'].unique()\n",
    "fake_subjects = df_fake['subject'].unique()\n",
    "\n",
    "print(\"True:\", true_subjects)\n",
    "print(\"Fake:\", fake_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c9336",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e782cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    for i in string.punctuation:\n",
    "        sentence = sentence.replace(i, \" \")\n",
    "    \n",
    "    document = nlp(sentence)\n",
    "    sentence = \" \".join(token.lemma_ for token in document)\n",
    "    sentence = \" \".join(word for word in sentence.split() if word not in english_stopwords)\n",
    "    sentence = re.sub(\"\\d\", \"\", sentence)\n",
    "    sentence = re.sub(\" +\", \" \", sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "df_true['title'] = df_true['title'].apply(clean_title)\n",
    "df_fake['title'] = df_fake['title'].apply(clean_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ho creato una funzione pi√π semplice, \n",
    "#poich√© applicare la funzione clean_title() anche sul testo portava via troppo tempo\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = \" \".join([word for word in text.split() if word not in english_stopwords])\n",
    "    return text\n",
    "\n",
    "df_true['text'] = df_true['text'].apply(clean_text)\n",
    "df_fake['text'] = df_fake['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true['title'] = df_true['title'].astype('string')\n",
    "df_true['text'] = df_true['text'].astype('string')\n",
    "df_fake['title'] = df_fake['title'].astype('string')\n",
    "df_fake['text'] = df_fake['text'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ce71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true['subject'] = df_true['subject'].astype('category')\n",
    "df_fake['subject'] = df_fake['subject'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c64ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true['date'] = df_true['date'].str.strip()\n",
    "df_true['date'] = pd.to_datetime(df_true['date'], errors='coerce')\n",
    "df_fake['date'] = df_fake['date'].str.strip()\n",
    "df_fake['date'] = pd.to_datetime(df_fake['date'], errors='coerce')\n",
    "print(df_true['date'].isna().sum())\n",
    "print(df_fake['date'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e095518b",
   "metadata": {},
   "source": [
    "### Le fake news sono pi√π frequenti in una determinata categoria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cbc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_counts = df_fake['subject'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=subject_counts.index, y=subject_counts.values, palette='viridis')\n",
    "plt.title('Frequenza di ciascun Subject')\n",
    "plt.xlabel('Subject')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df91429",
   "metadata": {},
   "source": [
    "### Per ogni categoria, ci sono argomenti che sono pi√π soggetti alle fake news?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31450921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Funzioni di Preprocessamento\n",
    "def sent_to_words(items):\n",
    "    for item in items:\n",
    "        yield(sp(item, deacc=True))\n",
    "        \n",
    "\n",
    "subjects = df_fake['subject'].unique()\n",
    "\n",
    "# Creazione del modello LDA per ciascun subset\n",
    "topic_models = {}\n",
    "for subject in subjects:\n",
    "    print(f\"Processing subject: {subject}\")\n",
    "    # Filtra il dataframe per il subject corrente\n",
    "    subset = df_fake[df_fake['subject'] == subject]\n",
    "    documents = subset['text']\n",
    "    \n",
    "    # Preprocessing del testo\n",
    "    data_words = list(sent_to_words(documents))\n",
    "    \n",
    "    # Creazione del dizionario e del corpus\n",
    "    id2word = corpora.Dictionary(data_words)\n",
    "    corpus = [id2word.doc2bow(text) for text in data_words]\n",
    "    \n",
    "    # Creazione e addestramento del modello LDA\n",
    "    lda_model = LdaMulticore(corpus=corpus, id2word=id2word, num_topics=3, passes=3)\n",
    "    topic_models[subject] = lda_model\n",
    "    pprint(lda_model.print_topics())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a0df02",
   "metadata": {},
   "source": [
    "Considerazioni Finali\n",
    "\n",
    "- Omogeneit√† Tematica: La forte omogeneit√† dei temi tra diverse categorie potrebbe indicare che le fake news tendono a sfruttare argomenti politicamente e socialmente sensibili che hanno un impatto trasversale, indipendentemente dalla specifica categoria di notizia.\n",
    "\n",
    "\n",
    "- Polarizzazione e Manipolazione: La presenza dominante di figure politiche chiave e l'uso di temi vaghi suggeriscono che le fake news sono costruite per polarizzare l'opinione pubblica e manipolare le emozioni, piuttosto che informare con contenuti specifici e dettagliati.\n",
    "\n",
    "\n",
    "- Raffinamento dell'Analisi: Per un'analisi pi√π approfondita, potrebbe essere utile confrontare questi risultati con quelli delle notizie vere nelle stesse categorie. Questo confronto potrebbe rivelare se e come le fake news si differenziano dalle notizie vere in termini di focus tematico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1770f22",
   "metadata": {},
   "source": [
    "### I titoli delle fake news presentano dei pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bdbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizzare CountVectorizer per contare le frequenze delle parole\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "title_matrix = vectorizer.fit_transform(df_fake['title'])\n",
    "sum_words = title_matrix.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Visualizzare le prime 10 parole pi√π frequenti\n",
    "print(words_freq[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865dd884",
   "metadata": {},
   "source": [
    "Commento:\n",
    "\n",
    "La prevalenza di nomi di personaggi politici indica che una parte significativa delle fake news √® centrata su figure politiche di spicco, in particolare legate alla politica statunitense. Questo suggerisce che le fake news tendono a concentrarsi su argomenti politicamente polarizzanti, usando figure controverse per attirare l'attenzione.\n",
    "\n",
    "Il risultato conferma che i titoli delle fake news presentano pattern riconoscibili, con un forte orientamento verso la politica e l'uso di linguaggio sensazionalistico. Questi pattern non solo riflettono i temi che probabilmente attraggono l'attenzione del pubblico, ma anche le tecniche utilizzate per massimizzare l'engagement, come l'uso di termini specifici che suggeriscono urgenza o esclusivit√†."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503f01f",
   "metadata": {},
   "source": [
    "### creare il modello di classificazione(logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true['truthful'] = 1\n",
    "df_fake[\"truthful\"] = 0\n",
    "\n",
    "df = pd.concat([df_true, df_fake], ignore_index=True)\n",
    "#df.drop([\"date\"], axis = 1, inplace = True)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df['subject'] = df['subject'].astype('category')\n",
    "\n",
    "# Calcolo della data mediana\n",
    "median_date = df['date'].median()\n",
    "# Imputazione dei valori mancanti con la data mediana\n",
    "df['date'].fillna(median_date, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de372bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23103d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7596d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre componenti dalla data\n",
    "def extract_date_features(X):\n",
    "    X['year'] = X['date'].dt.year\n",
    "    X['month'] = X['date'].dt.month\n",
    "    X['day_of_week'] = X['date'].dt.dayofweek\n",
    "    return X[['year', 'month', 'day_of_week']]\n",
    "\n",
    "X = df[['title', 'text', 'subject', 'date']]\n",
    "y = df['truthful']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('bow_title', CountVectorizer(stop_words='english'), 'title'),\n",
    "        ('bow_text', CountVectorizer(stop_words='english'), 'text'),\n",
    "        ('cat', OneHotEncoder(), ['subject']),\n",
    "        ('date_features', FunctionTransformer(extract_date_features), ['date'])\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Addestramento del modello sul training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Valutazione del modello sul validation set\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Valutazione delle prestazioni del modello sul validation set\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred)\n",
    "recall = recall_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Matrice di confusione sul validation set\n",
    "cm_val = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Visualizzazione della matrice di confusione come grafico\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'True'], yticklabels=['Fake', 'True'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for Validation Set')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione finale sul test set\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Valutazione delle prestazioni del modello sul test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "print(f'Test Set Metrics:')\n",
    "print(f'Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Precision: {test_precision:.2f}')\n",
    "print(f'Recall: {test_recall:.2f}')\n",
    "print(f'F1 Score: {test_f1:.2f}')\n",
    "\n",
    "# Matrice di confusione sul test set\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Visualizzazione della matrice di confusione come grafico per il test set\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens', xticklabels=['Fake', 'True'], yticklabels=['Fake', 'True'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72dd47",
   "metadata": {},
   "source": [
    "NOTA:\n",
    "\n",
    "Abbiamo applicato una trasformazione CountVectorizer sulle colonne testuali, ma ci sono anche altre trasformazioni possibili:\n",
    "- TfidfVectorizer\n",
    "- Word Embeddings\n",
    "- N-grams\n",
    "- HashingVectorizer\n",
    "- Feature Engineering con Meta-dati\n",
    "- Dimensionality Reduction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
